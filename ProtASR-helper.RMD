---
title: "ProtASR-Helper"
author: "Javad Khataei"
date: "March 20, 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# ProtASR Helper  
This file read ProtASR2.2 output and analysis the data. It find the aminoacids with the highest probability for each node. If the probability is less than 0.8, it will be market for further analysis.


### Load libraries and read files
```{r load libraries}
library(tidyverse)
library(data.table)
library(stringr)

```


```{r read-files}
file_name <- "ProtASR-sample-output.txt"
raw_lines <- readr::read_lines(file = file_name, skip_empty_rows = TRUE)
df <- data_frame(raw_lines)
```

### Which nodes?
The output file has a line similar to this, `Nodes 75 to 147 are ancestral`, which indicates which nodes to expect. 

```{r node-range}
first_word <-
    df$raw_lines[1:50] %>% stringr::str_split(n = 2, pattern = " ")


for (i in 1:50) {
    if (first_word[[i]][1] == "Nodes") {
        print(df$raw_lines[i])
        first_node_number <-
        stringr::str_split(string = raw_lines[i], pattern = " ")[[1]][2] %>%  
            as.numeric()
        last_node_number <-
        stringr::str_split(string = raw_lines[i], pattern = " ")[[1]][4] %>%  
            as.numeric()
        
    }
}
```


```{r to-dataframe}
# the plan was using one space(" ") as split pattern to convert the line to a series of colums but the number of  spaces changes in lines. The "site" increase and that reduces the spaces so can't use space to split.
# that why the following lines are commented out
# words_in_line <- df$raw_lines %>%
#     stringr::str_split_fixed(n= 40, pattern = " ") %>% 
#     as_tibble()
# 
# # Column V5 has the node number and a comma. delete the comma
# words_in_line$V5 <- words_in_line$V5 %>%
#     stringr::str_remove_all(",") 

# Trim the dat frame and select useful columns
#working_df <- words_in_line %>% select(c(V5, V16:V38))

# How to solve it?
# Split by :. Note there is a : in lines
words_in_line <- df$raw_lines %>%
    stringr::str_split_fixed(n= 2, pattern = ":") %>%
    as_data_frame()

# now use space to split and select the last solumn
# V5 has the node number and V14 the  letters
working_df <- words_in_line$V1 %>%
    stringr::str_split_fixed(n= 14, pattern = " ") %>%
    as_tibble() %>% 
    select(V5, V14)
# Node numbers have a comma
 working_df$V5 <- working_df$V5 %>%
    stringr::str_remove_all(",")
# Combine with the half after :
working_df <- cbind(working_df,words_in_line$V2)

```


### Clean dataset
Now that we have the important data in a dataframe, we need to clean the dataset.

# Important
Define the number of sites in this chunk first 

```{r}
site_number <- 217
```

```{r trim}
# Which row has the first node number in it? delete above it
first_row_index <- which.max(working_df$V5 == first_node_number)

# Last important row
last_row_index <- (site_number + 2) * (last_node_number - first_node_number + 1) + first_row_index

working_df <- working_df %>% slice(first_row_index:(last_row_index-1))

# Rename columns
colnames(working_df) <- c("node","letters","probs")

# Create site numbers
working_df$node <- rep(first_node_number:last_node_number, each= site_number + 2)

# Remove empty rows
working_df <- working_df %>%  dplyr::filter(working_df$letters != "") 
```


### Extract probabilities

All probabilities are in one column. First we create several columns from the prob column by splitting by space. Then name each column based on their aminoacids. Then split each by ( or even string index. Add a site number for each row. Then convert the data set from a fat dataset to a long one. At the end the data set will have these columns

|Node   |Letters    |Site    |Amino   |Prob   |
|-------|-----------|--------|--------|-------|
|75     |MMMM       |1       |M       |1.000  |
|75     |MMMM       |1       |R       |0.000  |




```{r extract-probs}

```


### Flag possible gaps or high probabilities

Focus on Prob column. Group by Site and then for each site order by prob and then add the first two one. If the sum is less than 0.8 then create a column and call it Alert. Else create the flag column and leave it empty.





